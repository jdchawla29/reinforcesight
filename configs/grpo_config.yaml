# configs/grpo_config.yaml
model:
  sft_checkpoint: "models/sft_ckpt"
  output_dir: "models/grpo_ckpt"
  
grpo:
  num_rollouts: 8
  num_candidates: 9
  discount_factor: 1.0
  kl_penalty: 0.12
  checkpoint_freq: 100
  
training:
  learning_rate: 3e-5
  batch_size: 32
  num_epochs: 5
  gradient_accumulation_steps: 2
  warmup_steps: 50
  max_grad_norm: 0.5
  
optimizer:
  type: "adamw"
  weight_decay: 0.01
  betas: [0.9, 0.999]
  
data:
  train_path: "datasets/train_rl.jsonl"
  val_path: "datasets/val_rl.jsonl"
  
reward:
  correct_answer_weight: 1.0
  incorrect_answer_weight: -0.5
  cot_quality_weight: 0.3
  consistency_weight: 0.2
  
logging:
  report_to: ["wandb", "tensorboard"]
  run_name: "spatial_vlm_grpo"
  project_name: "spatial_vlm"
  log_freq: 10